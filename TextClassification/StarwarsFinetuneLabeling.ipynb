{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "806b8901",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1faef0",
   "metadata": {},
   "source": [
    "# Module Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5dc0d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from transformers import pipeline\n",
    "import ast\n",
    "from collections import Counter\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b0d8e2",
   "metadata": {},
   "source": [
    "# Data Load and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "80467737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>[Republic]</td>\n",
       "      <td>All Stars Burn as One, The official anthem of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1534</th>\n",
       "      <td>[Creature]</td>\n",
       "      <td>bocatt, A tusked, leather-skinned predator fou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3142</th>\n",
       "      <td>[Clan]</td>\n",
       "      <td>Daughters of Allya, The name adopted by the Da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>[Character]</td>\n",
       "      <td>Aidus, A Rattataki guard who served Asajj Vent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8710</th>\n",
       "      <td>[Imperial, Faction]</td>\n",
       "      <td>Insurrection, This branch of the Pentastar Ali...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   labels                                               text\n",
       "idx                                                                         \n",
       "455            [Republic]  All Stars Burn as One, The official anthem of ...\n",
       "1534           [Creature]  bocatt, A tusked, leather-skinned predator fou...\n",
       "3142               [Clan]  Daughters of Allya, The name adopted by the Da...\n",
       "322           [Character]  Aidus, A Rattataki guard who served Asajj Vent...\n",
       "8710  [Imperial, Faction]  Insurrection, This branch of the Pentastar Ali..."
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starwars_df = pd.read_csv('./min_sample_train.csv',index_col='idx', converters={'labels': ast.literal_eval})\n",
    "starwars_df['text'] = starwars_df['term'] + ', ' + starwars_df['definition']\n",
    "starwars_df.drop(columns=['page','block','term','definition'],inplace=True)\n",
    "\n",
    "test_df = pd.read_csv('./sample_train.csv',index_col='idx')\n",
    "test_df['text'] = test_df['term'] + ', ' + test_df['definition']\n",
    "test_df.drop(columns=['page','block','term','definition'],inplace=True)\n",
    "\n",
    "starwars_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb55966",
   "metadata": {},
   "source": [
    "# Label Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf74f47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = sorted(list(set([label for labels in starwars_df['labels'] for label in labels])))\n",
    "id2label = {idx:label for idx,label in enumerate(all_labels)}\n",
    "label2id = {label:idx for idx,label in enumerate(all_labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20b70478",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We apply one-hot encoding for the labels\n",
    "def encode_labels(example):\n",
    "    #Sets the dimension for the example\n",
    "    encoded_labels = [0] * len(all_labels)\n",
    "    \n",
    "    for label in example['labels']:\n",
    "        encoded_labels[label2id[label]] = 1\n",
    "    \n",
    "    return {'labels': torch.tensor(encoded_labels, dtype=torch.float32)}\n",
    "    #return {'labels': encoded_labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6885e8d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b37f3a1158b04041a09c2508d9db94cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/99 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "starwars_dataset = Dataset.from_pandas(starwars_df)\n",
    "starwars_dataset = starwars_dataset.map(encode_labels,batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9608432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'labels': [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'text': 'Amee, One of Anakin Skywalker’s childhood friends in the slave quarters of Mos Espa, Amee worked as a house slave for a wealthy Toong couple. Her mother, Hala, was kidnapped in a slave raid by the pirate Krayn. She was three years younger than Anakin and attended the wedding of Shmi and Cliegg Lars.', 'idx': 521}\n"
     ]
    }
   ],
   "source": [
    "train_test_split = starwars_dataset.train_test_split(test_size=0.2, seed=42)\n",
    "train_dataset = train_test_split['train']\n",
    "eval_dataset = train_test_split['test']\n",
    "\n",
    "print(train_dataset[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c0eb3eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>[Republic]</td>\n",
       "      <td>All Stars Burn as One, The official anthem of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1534</th>\n",
       "      <td>[Creature]</td>\n",
       "      <td>bocatt, A tusked, leather-skinned predator fou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3142</th>\n",
       "      <td>[Clan]</td>\n",
       "      <td>Daughters of Allya, The name adopted by the Da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>[Character]</td>\n",
       "      <td>Aidus, A Rattataki guard who served Asajj Vent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8710</th>\n",
       "      <td>[Imperial, Faction]</td>\n",
       "      <td>Insurrection, This branch of the Pentastar Ali...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   labels                                               text\n",
       "idx                                                                         \n",
       "455            [Republic]  All Stars Burn as One, The official anthem of ...\n",
       "1534           [Creature]  bocatt, A tusked, leather-skinned predator fou...\n",
       "3142               [Clan]  Daughters of Allya, The name adopted by the Da...\n",
       "322           [Character]  Aidus, A Rattataki guard who served Asajj Vent...\n",
       "8710  [Imperial, Faction]  Insurrection, This branch of the Pentastar Ali..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starwars_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44255fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = 'bert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27a286a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples['text'], \n",
    "        truncation=True, \n",
    "        padding=\"max_length\",\n",
    "        max_length=128\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b06bf139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63f5d610f0b54f9bb61f99f7de18658c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/79 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0f85d6067324a54838ca802c47ab6a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_eval_dataset = eval_dataset.map(tokenize_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "377ddc61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['labels', 'text', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 79\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01664edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train_dataset = tokenized_train_dataset.remove_columns(['text','idx'])\n",
    "tokenized_eval_dataset = tokenized_eval_dataset.remove_columns(['text','idx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ac1fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train_dataset.set_format('torch',columns=['input_ids','attention_mask','token_type_ids','labels'])\n",
    "tokenized_eval_dataset.set_format('torch',columns=['input_ids','attention_mask','token_type_ids','labels'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c96f536e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, hamming_loss #multi-label metrics\n",
    "metric = evaluate.load('f1')\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    \n",
    "    sigmoid = np.vectorize(lambda x: 1/(1 + np.exp(-x)))\n",
    "    predictions = (sigmoid(logits) >0.5).astype(int)\n",
    "    \n",
    "    f1_micro = f1_score(labels, predictions, average='macro', zero_division=0)\n",
    "    precision_micro = precision_score(labels, predictions, average='micro')\n",
    "    recall_micro = recall_score(labels,predictions,average='micro')\n",
    "    \n",
    "    f1_macro = f1_score(labels, predictions,average='macro', zero_division=0)\n",
    "    precision_macro = precision_score(labels, predictions, average='macro', zero_division=0)\n",
    "    recall_macro = recall_score(labels, predictions, average='macro', zero_division=0)\n",
    "    \n",
    "    h_loss = hamming_loss(labels, predictions)\n",
    "    \n",
    "    return {\n",
    "        'f1_micro': f1_micro,\n",
    "        'precision_micro': precision_micro,\n",
    "        'recall_micro': recall_micro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'precision_macro': precision_macro,\n",
    "        'recall_macro': recall_macro,\n",
    "        'hamming_loss': h_loss\n",
    "    }\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0436d864",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    num_labels=len(all_labels),\n",
    "    problem_type='multi_label_classification',\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dbd2f5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4f66c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=6,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100,\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='f1_micro',\n",
    "    greater_is_better=True,\n",
    "    push_to_hub=False,\n",
    "    report_to='tensorboard'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2de5b9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset = tokenized_train_dataset,\n",
    "    eval_dataset = tokenized_eval_dataset,\n",
    "    #tokenizer = tokenizer,\n",
    "    data_collator = data_collator,\n",
    "    compute_metrics = compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6c8264ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 01:09, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>Precision Micro</th>\n",
       "      <th>Recall Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>Precision Macro</th>\n",
       "      <th>Recall Macro</th>\n",
       "      <th>Hamming Loss</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "      <th>Steps Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.655893</td>\n",
       "      <td>0.052777</td>\n",
       "      <td>0.042857</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.052777</td>\n",
       "      <td>0.038708</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.316000</td>\n",
       "      <td>0.222100</td>\n",
       "      <td>90.046000</td>\n",
       "      <td>9.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.649696</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.030534</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.016381</td>\n",
       "      <td>0.105000</td>\n",
       "      <td>0.306000</td>\n",
       "      <td>0.203700</td>\n",
       "      <td>98.172000</td>\n",
       "      <td>9.817000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.640263</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.026087</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>0.085000</td>\n",
       "      <td>0.278000</td>\n",
       "      <td>0.202800</td>\n",
       "      <td>98.632000</td>\n",
       "      <td>9.863000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.628842</td>\n",
       "      <td>0.007619</td>\n",
       "      <td>0.018692</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.007619</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.266000</td>\n",
       "      <td>0.205900</td>\n",
       "      <td>97.123000</td>\n",
       "      <td>9.712000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.616644</td>\n",
       "      <td>0.007619</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.007619</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.201600</td>\n",
       "      <td>99.197000</td>\n",
       "      <td>9.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.605180</td>\n",
       "      <td>0.016508</td>\n",
       "      <td>0.042105</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.016508</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.234000</td>\n",
       "      <td>0.230100</td>\n",
       "      <td>86.912000</td>\n",
       "      <td>8.691000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 01:25]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()\n",
    "results = trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4bb24193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results: {'eval_loss': 0.6558932065963745, 'eval_f1_micro': 0.05277684407096172, 'eval_precision_micro': 0.04285714285714286, 'eval_recall_micro': 0.2, 'eval_f1_macro': 0.05277684407096172, 'eval_precision_macro': 0.03870843776106934, 'eval_recall_macro': 0.15, 'eval_hamming_loss': 0.316, 'eval_runtime': 0.4385, 'eval_samples_per_second': 45.606, 'eval_steps_per_second': 4.561, 'epoch': 6.0}\n"
     ]
    }
   ],
   "source": [
    "results = trainer.evaluate()\n",
    "print('Evaluation results:', results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3962917c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./fine_tuned_star_wars_classifier/tokenizer_config.json',\n",
       " './fine_tuned_star_wars_classifier/special_tokens_map.json',\n",
       " './fine_tuned_star_wars_classifier/vocab.txt',\n",
       " './fine_tuned_star_wars_classifier/added_tokens.json',\n",
       " './fine_tuned_star_wars_classifier/tokenizer.json')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_save_path = './fine_tuned_star_wars_classifier'\n",
    "trainer.save_model(model_save_path)\n",
    "tokenizer.save_pretrained(model_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12796735",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model_path = './fine_tuned_star_wars_classifier'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path, problem_type='multi_label_classification')\n",
    "\n",
    "classifier = pipeline(\n",
    "    'text-classification',\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    top_k=None,\n",
    "    \n",
    "    max_length=512,\n",
    "    truncation=True,\n",
    "    padding = True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0a597c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character\n",
      "0.6502765417098999\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text = 'bocatt, A tusked, leather-skinned predator found on Tatooine.'\n",
    "prediction_results = classifier(text)\n",
    "\n",
    "list_of_label_dicts = prediction_results[0]\n",
    "\n",
    "predicted_scores_pipeline = []\n",
    "predicted_labels_pipeline = []\n",
    "for label_info in list_of_label_dicts:\n",
    "    if label_info['score'] > 0.65:\n",
    "        print(label_info['label'])\n",
    "        print(label_info['score'])\n",
    "    \n",
    "    #predicted_labels_pipeline.append(label_info['label'])\n",
    "    #predicted_scores_pipeline.append(label_info['score'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9abcaa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(text):\n",
    "    prediction_results = classifier(text)\n",
    "    \n",
    "    list_of_label_dicts = prediction_results[0]\n",
    "    \n",
    "    predicted_scores_pipeline = []\n",
    "    predicted_labels_pipeline = []\n",
    "    for label_info in list_of_label_dicts:\n",
    "        if label_info['score'] > 0.65:\n",
    "            predicted_labels_pipeline.append(label_info['label'])\n",
    "            predicted_scores_pipeline.append(label_info['score'])\n",
    "    \n",
    "    return predicted_labels_pipeline, predicted_scores_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8959be",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = test_df['text'].apply(prediction)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8596b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[['predicted_labels','predicted_scores']] = pd.DataFrame(temp.tolist(),index=test_df.index).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0da38e49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>predicted_labels</th>\n",
       "      <th>predicted_scores</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>All Stars Burn as One, The official anthem of ...</td>\n",
       "      <td>[Rebel, Ship]</td>\n",
       "      <td>[0.7018588185310364, 0.6653783917427063]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1534</th>\n",
       "      <td>bocatt, A tusked, leather-skinned predator fou...</td>\n",
       "      <td>[Character]</td>\n",
       "      <td>[0.6502765417098999]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3142</th>\n",
       "      <td>Daughters of Allya, The name adopted by the Da...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>Aidus, A Rattataki guard who served Asajj Vent...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8710</th>\n",
       "      <td>Insurrection, This branch of the Pentastar Ali...</td>\n",
       "      <td>[Rebel]</td>\n",
       "      <td>[0.6791582703590393]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>Aora, Aruk Besadii, A corpulent Hutt on Nal Hu...</td>\n",
       "      <td>[Rebel]</td>\n",
       "      <td>[0.674552321434021]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1852</th>\n",
       "      <td>B’wuf, A senior technical analyst aboard the S...</td>\n",
       "      <td>[Rebel]</td>\n",
       "      <td>[0.6703217625617981]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11510</th>\n",
       "      <td>manadept, One of the many types of domesticate...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>AAP blaster box, A series of strap-on laser we...</td>\n",
       "      <td>[Rebel]</td>\n",
       "      <td>[0.6612579226493835]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14088</th>\n",
       "      <td>Oryon, One of the best Republic spies during t...</td>\n",
       "      <td>[Rebel]</td>\n",
       "      <td>[0.7099098563194275]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text predicted_labels  \\\n",
       "idx                                                                         \n",
       "455    All Stars Burn as One, The official anthem of ...    [Rebel, Ship]   \n",
       "1534   bocatt, A tusked, leather-skinned predator fou...      [Character]   \n",
       "3142   Daughters of Allya, The name adopted by the Da...               []   \n",
       "322    Aidus, A Rattataki guard who served Asajj Vent...               []   \n",
       "8710   Insurrection, This branch of the Pentastar Ali...          [Rebel]   \n",
       "...                                                  ...              ...   \n",
       "671    Aora, Aruk Besadii, A corpulent Hutt on Nal Hu...          [Rebel]   \n",
       "1852   B’wuf, A senior technical analyst aboard the S...          [Rebel]   \n",
       "11510  manadept, One of the many types of domesticate...               []   \n",
       "52     AAP blaster box, A series of strap-on laser we...          [Rebel]   \n",
       "14088  Oryon, One of the best Republic spies during t...          [Rebel]   \n",
       "\n",
       "                               predicted_scores  \n",
       "idx                                              \n",
       "455    [0.7018588185310364, 0.6653783917427063]  \n",
       "1534                       [0.6502765417098999]  \n",
       "3142                                         []  \n",
       "322                                          []  \n",
       "8710                       [0.6791582703590393]  \n",
       "...                                         ...  \n",
       "671                         [0.674552321434021]  \n",
       "1852                       [0.6703217625617981]  \n",
       "11510                                        []  \n",
       "52                         [0.6612579226493835]  \n",
       "14088                      [0.7099098563194275]  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6e18a0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('./predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fd473c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "# hook tqdm into pandas\n",
    "tqdm.pandas()\n",
    "starwars_df['classification'] = starwars_df['text'].progress_apply(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
